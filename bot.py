import logging
import hashlib
import json
import aiosqlite 
import requests
import asyncio
from datetime import datetime
from collections import deque
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command 
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup 
from aiogram.exceptions import TelegramBadRequest
from config import (
    TELEGRAM_BOT_TOKEN, OLLAMA_URL, DEFAULT_MODEL,
    DEEP_MODEL, DB_PATH, MAX_STREAM_TIMEOUT
)
from rag_manager import rag_manager

# === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
CONTEXT_WINDOW = 10
MAX_TELEGRAM_LENGTH = 4096
CURRENT_TEMPERATURE = 0.8
RAG_ENABLED = False  # –ë—É–¥–µ—Ç –≤–∫–ª—é—á–µ–Ω–æ –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏

# === –ù–ê–°–¢–†–û–ô–ö–ò –û–ß–ï–†–ï–î–ï–ô ===
MAX_CONCURRENT_REQUESTS = 1  # –í–ê–ñ–ù–û: 1 –¥–ª—è CPU! (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)
MAX_QUEUE_SIZE = 10          # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏
REQUEST_TIMEOUT = 600        # –¢–∞–π–º–∞—É—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å (10 –º–∏–Ω—É—Ç)

# === –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ì–†–£–ü–ü ===
GROUP_MODE_MENTION_ONLY = True
GROUP_CONTEXT_ENABLED = True
GROUP_ADMIN_ONLY_COMMANDS = ["clear", "temp", "stats", "rag_init", "rag_clear"]

# === –î–û–°–¢–£–ü–ù–´–ï –ú–û–î–ï–õ–ò ===
AVAILABLE_MODELS = [
    "qwen2.5:7b-instruct-q4_K_M",
    "mistral:7b-instruct-q4_K_M"
]

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É data –¥–ª—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
import os
os.makedirs("./data", exist_ok=True)

# === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bot.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("supreme")

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ===
bot = Bot(token=TELEGRAM_BOT_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)
db_conn = None

# === FSM States ===
class BotStates(StatesGroup):
    deep_mode = State()

# ============================================
# –°–ò–°–¢–ï–ú–ê –û–ß–ï–†–ï–î–ï–ô
# ============================================

class RequestQueue:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥—å—é –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ LLM"""
    
    def __init__(self, max_concurrent: int = 2, max_queue_size: int = 10):
        self.max_concurrent = max_concurrent
        self.max_queue_size = max_queue_size
        self.active_requests = 0
        self.queue = deque()
        self.lock = asyncio.Lock()
        self.queue_stats = {
            'total_processed': 0,
            'total_queued': 0,
            'total_rejected': 0,
            'avg_wait_time': 0
        }
    
    async def can_process(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å —Å–µ–π—á–∞—Å"""
        async with self.lock:
            return self.active_requests < self.max_concurrent
    
    async def add_to_queue(self, request_data: dict) -> int:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ –æ—á–µ—Ä–µ–¥—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–∑–∏—Ü–∏—é"""
        async with self.lock:
            if len(self.queue) >= self.max_queue_size:
                self.queue_stats['total_rejected'] += 1
                return -1  # –û—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞
            
            request_data['queued_at'] = datetime.now()
            self.queue.append(request_data)
            self.queue_stats['total_queued'] += 1
            position = len(self.queue)
            logger.info(f"üìã Request added to queue. Position: {position}, Queue size: {len(self.queue)}")
            return position
    
    async def start_processing(self):
        """–û—Ç–º–µ—á–∞–µ—Ç –Ω–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""
        async with self.lock:
            self.active_requests += 1
            logger.info(f"üîÑ Active requests: {self.active_requests}/{self.max_concurrent}")
    
    async def finish_processing(self):
        """–û—Ç–º–µ—á–∞–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""
        async with self.lock:
            self.active_requests = max(0, self.active_requests - 1)
            self.queue_stats['total_processed'] += 1
            logger.info(f"‚úÖ Request finished. Active requests: {self.active_requests}/{self.max_concurrent}")
    
    async def get_next_request(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å –∏–∑ –æ—á–µ—Ä–µ–¥–∏"""
        async with self.lock:
            if self.queue:
                request = self.queue.popleft()
                wait_time = (datetime.now() - request['queued_at']).total_seconds()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è
                total = self.queue_stats['total_processed']
                if total > 0:
                    avg = self.queue_stats['avg_wait_time']
                    self.queue_stats['avg_wait_time'] = (avg * total + wait_time) / (total + 1)
                else:
                    self.queue_stats['avg_wait_time'] = wait_time
                
                logger.info(f"‚è±Ô∏è Request waited {wait_time:.1f}s in queue")
                return request
            return None
    
    async def get_queue_info(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –æ—á–µ—Ä–µ–¥–∏"""
        async with self.lock:
            return {
                'active': self.active_requests,
                'queued': len(self.queue),
                'max_concurrent': self.max_concurrent,
                'stats': self.queue_stats.copy()
            }

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ—á–µ—Ä–µ–¥—å
request_queue = RequestQueue(max_concurrent=MAX_CONCURRENT_REQUESTS, max_queue_size=MAX_QUEUE_SIZE)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ (–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ —Ñ–æ–Ω–µ)
async def queue_processor():
    """–§–æ–Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏"""
    logger.info("üîÑ Queue processor started")
    
    while True:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ–º –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            if await request_queue.can_process():
                request_data = await request_queue.get_next_request()
                
                if request_data:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
                    asyncio.create_task(process_queued_request(request_data))
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
            await asyncio.sleep(0.5)
            
        except Exception as e:
            logger.exception(f"Error in queue processor: {e}")
            await asyncio.sleep(1)

async def process_queued_request(request_data: dict):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∏–∑ –æ—á–µ—Ä–µ–¥–∏"""
    await request_queue.start_processing()
    
    try:
        await process_message(
            request_data['message'],
            request_data['model'],
            request_data['is_deep']
        )
    except Exception as e:
        logger.exception(f"Error processing queued request: {e}")
        try:
            await request_data['message'].reply(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        except:
            pass
    finally:
        await request_queue.finish_processing()

# ============================================
# –§–£–ù–ö–¶–ò–ò –†–ê–ë–û–¢–´ –° –ì–†–£–ü–ü–ê–ú–ò
# ============================================

async def is_group_chat(message: types.Message) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —á–∞—Ç –≥—Ä—É–ø–ø–æ–≤—ã–º."""
    return message.chat.type in ["group", "supergroup"]

async def is_user_admin(message: types.Message) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º –≥—Ä—É–ø–ø—ã."""
    if not await is_group_chat(message):
        return True
    
    try:
        member = await bot.get_chat_member(message.chat.id, message.from_user.id)
        return member.status in ["creator", "administrator"]
    except Exception as e:
        logger.error(f"Error checking admin status: {e}")
        return False

def is_bot_mentioned(message: types.Message) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —É–ø–æ–º—è–Ω—É—Ç –ª–∏ –±–æ—Ç –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏."""
    if not message.text:
        return False
    
    if message.entities:
        for entity in message.entities:
            if entity.type == "mention":
                mention = message.text[entity.offset:entity.offset + entity.length]
                bot_username = bot._me.username if hasattr(bot, '_me') else None
                if bot_username and mention == f"@{bot_username}":
                    return True
    
    if message.reply_to_message and message.reply_to_message.from_user.is_bot:
        return True
    
    return False

def remove_bot_mention(text: str, bot_username: str = None) -> str:
    """–£–¥–∞–ª—è–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –±–æ—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    if not bot_username:
        return text
    text = text.replace(f"@{bot_username}", "").strip()
    return text

async def get_group_context_id(message: types.Message) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç ID –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–≥—Ä—É–ø–ø—ã –∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)."""
    if await is_group_chat(message):
        return message.chat.id
    return message.from_user.id

# ============================================
# –§–£–ù–ö–¶–ò–ò –†–ê–ë–û–¢–´ –° OLLAMA
# ============================================

async def check_ollama() -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ."""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.ok:
            models = response.json().get('models', [])
            logger.info(f"‚úÖ Ollama –¥–æ—Å—Ç—É–ø–Ω–∞. –ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models)}")
            
            model_names = [m.get('name', '') for m in models]
            
            if not any(DEFAULT_MODEL in name for name in model_names):
                logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {DEFAULT_MODEL} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            if not any(DEEP_MODEL in name for name in model_names):
                logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {DEEP_MODEL} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            return True
    except requests.exceptions.ConnectionError:
        logger.error("‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞! –ó–∞–ø—É—Å—Ç–∏: ollama serve")
        return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Ollama: {e}")
        return False

def call_ollama_stream(model: str, prompt: str, timeout: int = REQUEST_TIMEOUT, temperature: float = 0.8) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Ollama –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç."""
    logger.info(f"üîó Connecting to Ollama: {OLLAMA_URL}")
    logger.info(f"üß† Model: {model}, Temperature: {temperature}")
    
    payload = {
        "model": model,
        "prompt": prompt,
        "temperature": temperature,
        "top_p": 0.95,
        "top_k": 50
    }
    
    try:
        logger.info(f"üì° Sending request to Ollama...")
        response = requests.post(OLLAMA_URL, json=payload, stream=True, timeout=timeout)
        response.raise_for_status()
        
        logger.info(f"üì• Receiving stream from Ollama...")
        full_response = ""
        chunk_count = 0
        
        for line in response.iter_lines(decode_unicode=True):
            if not line:
                continue
            try:
                obj = json.loads(line)
                if "response" in obj:
                    full_response += obj["response"]
                    chunk_count += 1
                    if chunk_count % 10 == 0:
                        logger.debug(f"üìä Received {chunk_count} chunks, {len(full_response)} chars so far")
                if obj.get("error"):
                    logger.error(f"‚ùå Ollama error: {obj['error']}")
                    return f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏ Ollama: {obj['error']}"
            except json.JSONDecodeError:
                continue
        
        logger.info(f"‚úÖ Stream complete: {chunk_count} chunks, {len(full_response)} chars total")
        return full_response.strip()
        
    except requests.exceptions.Timeout:
        logger.error(f"‚è±Ô∏è Timeout after {timeout}s")
        return "‚è±Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω —Ç–∞–π–º–∞—É—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç Ollama."
    except Exception as e:
        logger.exception(f"‚ùå Ollama call failed: {e}")
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏: {e}"

def call_ollama_with_context(model: str, prompt: str, context_docs: list, timeout: int = REQUEST_TIMEOUT, temperature: float = 0.8) -> str:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Ollama —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    
    Args:
        model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        prompt: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        context_docs: –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ RAG
        timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        
    Returns:
        –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
    """
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    context_parts = []
    for i, doc in enumerate(context_docs, 1):
        source = doc['source']
        content = doc['content']
        context_parts.append(f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {i}: {source}]\n{content}\n")
    
    context_text = "\n---\n".join(context_parts)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    full_prompt = (
        f"–¢—ã - –¢–û–†, AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Å–ª–µ–¥—É—é—â–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º:\n\n"
        f"{context_text}\n"
        f"---\n\n"
        f"–ò—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —ç—Ç–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n"
        f"–ï—Å–ª–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.\n"
        f"–£–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –æ—Ç–∫—É–¥–∞ –≤–∑—è—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è.\n\n"
        f"–í–æ–ø—Ä–æ—Å: {prompt}\n"
        f"–û—Ç–≤–µ—Ç:"
    )
    
    # –í—ã–∑—ã–≤–∞–µ–º –æ–±—ã—á–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    return call_ollama_stream(model, full_prompt, timeout, temperature)

# ============================================
# –§–£–ù–ö–¶–ò–ò –†–ê–ë–û–¢–´ –° –ë–î
# ============================================

async def init_db():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö."""
    global db_conn
    db_conn = await aiosqlite.connect(DB_PATH)
    
    await db_conn.execute("""
        CREATE TABLE IF NOT EXISTS cache (
            prompt_hash TEXT PRIMARY KEY,
            prompt TEXT,
            response TEXT,
            model TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    await db_conn.execute("""
        CREATE TABLE IF NOT EXISTS logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            prompt TEXT,
            response TEXT,
            model TEXT,
            ts DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    await db_conn.execute("""
        CREATE TABLE IF NOT EXISTS user_activity (
            user_id INTEGER PRIMARY KEY,
            last_seen DATETIME DEFAULT CURRENT_TIMESTAMP,
            message_count INTEGER DEFAULT 0
        )
    """)
    
    await db_conn.commit()
    logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞.")

def prompt_hash(prompt: str, model: str) -> str:
    return hashlib.sha256((prompt + "|" + model).encode("utf-8")).hexdigest()

async def get_cached(prompt: str, model: str):
    h = prompt_hash(prompt, model)
    async with db_conn.execute("SELECT response FROM cache WHERE prompt_hash = ?", (h,)) as cursor:
        result = await cursor.fetchone()
        return result[0] if result else None

async def save_cache(prompt: str, model: str, response: str):
    h = prompt_hash(prompt, model)
    await db_conn.execute(
        "INSERT OR REPLACE INTO cache (prompt_hash, prompt, response, model) VALUES (?, ?, ?, ?)",
        (h, prompt, response, model)
    )
    await db_conn.commit()

async def log_dialog(context_id: int, prompt: str, response: str, model: str):
    await db_conn.execute(
        "INSERT INTO logs (user_id, prompt, response, model) VALUES (?, ?, ?, ?)",
        (context_id, prompt, response, model)
    )
    await db_conn.commit()

async def update_user_activity(user_id: int):
    await db_conn.execute("""
        INSERT INTO user_activity (user_id, last_seen, message_count) 
        VALUES (?, CURRENT_TIMESTAMP, 1)
        ON CONFLICT(user_id) DO UPDATE SET 
            last_seen = CURRENT_TIMESTAMP,
            message_count = message_count + 1
    """, (user_id,))
    await db_conn.commit()

async def get_dialogue_context(context_id: int) -> str:
    query = """
        SELECT prompt, response FROM logs
        WHERE user_id = ?
        ORDER BY id DESC
        LIMIT ?
    """
    async with db_conn.execute(query, (context_id, CONTEXT_WINDOW * 2)) as cursor:
        rows = await cursor.fetchall()

    if not rows:
        return ""
    
    rows.reverse()
    
    context_parts = []
    for prompt, response in rows:
        cleaned_response = response.replace(" (cache)", "")
        context_parts.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {prompt}\n")
        context_parts.append(f"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {cleaned_response}\n")
        
    return "".join(context_parts)

# ============================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ============================================

def split_text(text: str, max_length: int = MAX_TELEGRAM_LENGTH) -> list[str]:
    if not text:
        return [""]
    
    chunks = []
    while len(text) > max_length:
        split_index = text.rfind('\n\n', 0, max_length)
        if split_index == -1:
            split_index = text.rfind('. ', 0, max_length)
        if split_index == -1:
            split_index = text.rfind(' ', 0, max_length)
        if split_index == -1 or split_index == 0:
            split_index = max_length

        chunks.append(text[:split_index].strip())
        text = text[split_index:].strip()
    
    if text:
        chunks.append(text)
    
    return chunks

async def send_long_message(message: types.Message, text: str, parse_mode: str = "Markdown"):
    chunks = split_text(text)
    
    for i, chunk in enumerate(chunks):
        try:
            if i == 0:
                await message.reply(chunk, parse_mode=parse_mode)
            else:
                await message.answer(chunk, parse_mode=parse_mode)
        except TelegramBadRequest:
            logger.warning(f"–û—à–∏–±–∫–∞ Markdown –≤ —á–∞—Å—Ç–∏ {i+1}. –û—Ç–ø—Ä–∞–≤–∫–∞ –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
            if i == 0:
                await message.reply(chunk, parse_mode=None)
            else:
                await message.answer(chunk, parse_mode=None)

async def show_typing_periodic(chat_id: int, stop_event: asyncio.Event):
    while not stop_event.is_set():
        try:
            await bot.send_chat_action(chat_id, "typing")
        except Exception:
            pass
        await asyncio.sleep(5)

# ============================================
# –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î
# ============================================

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    is_group = await is_group_chat(message)
    
    if is_group:
        await message.reply(
            "üëã –ü—Ä–∏–≤–µ—Ç! –Ø **–¢–û–†** (–¢–≤–æ—Ä—á–µ—Å–∫–∏–π –û–ª–∏–º–ø–∏–π—Å–∫–∏–π –†–∞–∑—É–º).\n\n"
            "–£–ø–æ–º–Ω–∏—Ç–µ –º–µ–Ω—è (@bot) –∏–ª–∏ –æ—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –º–æ—ë —Å–æ–æ–±—â–µ–Ω–∏–µ!\n\n"
            "–ö–æ–º–∞–Ω–¥—ã: /help /queue",
            parse_mode="Markdown"
        )
    else:
        queue_info = await request_queue.get_queue_info()
        rag_status = "üü¢ –ê–∫—Ç–∏–≤–Ω–∞" if RAG_ENABLED else "üî¥ –ù–µ–∞–∫—Ç–∏–≤–Ω–∞"
        
        await message.reply(
            "‚ö° **–¢–û–†** - –¢–≤–æ—Ä—á–µ—Å–∫–∏–π –û–ª–∏–º–ø–∏–π—Å–∫–∏–π –†–∞–∑—É–º\n\n"
            "–ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ –±–∞–∑–µ LLM.\n\n"
            "üí¨ –ü—Ä–æ—Å—Ç–æ –ø–∏—à–∏ - —è –æ—Ç–≤–µ—á—É\n"
            "üî• /deep - –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å\n"
            "üóëÔ∏è /clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é\n"
            "üìä /stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "üìã /queue - —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏\n"
            "üå°Ô∏è /temp <—á–∏—Å–ª–æ> - —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (0.1-1.5)\n"
            "üìö /ask <–≤–æ–ø—Ä–æ—Å> - –≤–æ–ø—Ä–æ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º\n"
            "üîß /rag_init - –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å RAG\n"
            "üìä /rag_stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
            "‚ùì /about - –æ–±–æ –º–Ω–µ\n"
            "‚ùì /help - —Å–ø—Ä–∞–≤–∫–∞\n\n"
            f"üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {CURRENT_TEMPERATURE}\n"
            f"üìö RAG: {rag_status}\n"
            f"üìã –û—á–µ—Ä–µ–¥—å: {queue_info['queued']}, –ê–∫—Ç–∏–≤–Ω—ã—Ö: {queue_info['active']}",
            parse_mode="Markdown"
        )

@dp.message(Command("queue"))
async def cmd_queue(message: types.Message):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    info = await request_queue.get_queue_info()
    stats = info['stats']
    
    await message.reply(
        f"üìã **–°–æ—Å—Ç–æ—è–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏:**\n\n"
        f"üîÑ –ê–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {info['active']}/{info['max_concurrent']}\n"
        f"‚è≥ –í –æ—á–µ—Ä–µ–¥–∏: {info['queued']}\n\n"
        f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n"
        f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['total_processed']}\n"
        f"üì• –ü–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å: {stats['total_queued']}\n"
        f"‚ùå –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {stats['total_rejected']}\n"
        f"‚è±Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è: {stats['avg_wait_time']:.1f}—Å",
        parse_mode="Markdown"
    )

@dp.message(Command("clear"))
async def cmd_clear(message: types.Message):
    if await is_group_chat(message):
        if not await is_user_admin(message):
            await message.reply("‚õî –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤")
            return
    
    context_id = await get_group_context_id(message)
    await db_conn.execute("DELETE FROM logs WHERE user_id = ?", (context_id,))
    await db_conn.commit()
    
    chat_type = "–≥—Ä—É–ø–ø—ã" if await is_group_chat(message) else "–¥–∏–∞–ª–æ–≥–∞"
    await message.reply(f"üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è {chat_type} –æ—á–∏—â–µ–Ω–∞!")

@dp.message(Command("stats"))
async def cmd_stats(message: types.Message):
    if await is_group_chat(message):
        if not await is_user_admin(message):
            await message.reply("‚õî –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤")
            return
    
    context_id = await get_group_context_id(message)
    
    async with db_conn.execute("SELECT COUNT(*) FROM logs WHERE user_id = ?", (context_id,)) as cursor:
        messages_count = (await cursor.fetchone())[0]
    
    async with db_conn.execute("SELECT COUNT(*) FROM cache") as cursor:
        cache_count = (await cursor.fetchone())[0]
    
    queue_info = await request_queue.get_queue_info()
    
    await message.reply(
        f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n\n"
        f"üí¨ –°–æ–æ–±—â–µ–Ω–∏–π: {messages_count}\n"
        f"üóÑÔ∏è –í –∫—ç—à–µ: {cache_count}\n"
        f"üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç: {CONTEXT_WINDOW} –ø–∞—Ä\n"
        f"üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {CURRENT_TEMPERATURE}\n"
        f"üìã –û—á–µ—Ä–µ–¥—å: {queue_info['active']}/{queue_info['max_concurrent']} –∞–∫—Ç–∏–≤–Ω—ã—Ö",
        parse_mode="Markdown"
    )

@dp.message(Command("temp"))
async def cmd_temp(message: types.Message):
    if await is_group_chat(message):
        if not await is_user_admin(message):
            await message.reply("‚õî –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤")
            return
    
    global CURRENT_TEMPERATURE
    
    try:
        parts = message.text.split()
        if len(parts) < 2:
            await message.reply("üå°Ô∏è –§–æ—Ä–º–∞—Ç: `/temp 0.8`", parse_mode="Markdown")
            return
        
        temp = float(parts[1])
        if temp < 0.1 or temp > 1.5:
            await message.reply("‚ö†Ô∏è –û—Ç 0.1 –¥–æ 1.5")
            return
        
        CURRENT_TEMPERATURE = temp
        await message.reply(f"üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: **{temp}**", parse_mode="Markdown")
    except ValueError:
        await message.reply("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç", parse_mode="Markdown")

@dp.message(Command("about"))
async def cmd_about(message: types.Message):
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–æ—Ç–µ"""
    rag_status = "üü¢ –ê–∫—Ç–∏–≤–Ω–∞" if RAG_ENABLED else "üî¥ –ù–µ–∞–∫—Ç–∏–≤–Ω–∞"
    
    await message.reply(
        "‚ö° **–¢–û–†** - –¢–≤–æ—Ä—á–µ—Å–∫–∏–π –û–ª–∏–º–ø–∏–π—Å–∫–∏–π –†–∞–∑—É–º\n\n"
        "ü§ñ –Ø - AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ –±–∞–∑–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM)\n\n"
        "üí™ **–ú–æ–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n"
        "‚Ä¢ –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ª—é–±–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏\n"
        "‚Ä¢ –ü–æ–º–æ—â—å —Å –∑–∞–¥–∞—á–∞–º–∏ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n"
        "‚Ä¢ –¢–≤–æ—Ä—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–¥–µ–π\n"
        "‚Ä¢ –†–∞–±–æ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–∏–∞–ª–æ–≥–∞\n"
        "‚Ä¢ –î–≤–∞ —Ä–µ–∂–∏–º–∞: –æ–±—ã—á–Ω—ã–π –∏ Deep (–º–æ—â–Ω—ã–π)\n"
        "‚Ä¢ –ü–æ–∏—Å–∫ –ø–æ –≤–∞—à–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º —á–µ—Ä–µ–∑ RAG\n\n"
        "üß† **–ú–æ–¥–µ–ª–∏:**\n"
        f"‚Ä¢ –û–±—ã—á–Ω–∞—è: {DEFAULT_MODEL}\n"
        f"‚Ä¢ Deep: {DEEP_MODEL}\n\n"
        f"üìö **RAG —Å–∏—Å—Ç–µ–º–∞:** {rag_status}\n\n"
        "‚öôÔ∏è **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**\n"
        "‚Ä¢ Ollama (–ª–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ LLM)\n"
        "‚Ä¢ GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ\n"
        "‚Ä¢ –°–∏—Å—Ç–µ–º–∞ –æ—á–µ—Ä–µ–¥–µ–π\n"
        "‚Ä¢ –£–º–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ\n"
        "‚Ä¢ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π\n\n"
        "üí° –°–æ–∑–¥–∞–Ω –¥–ª—è –ø–æ–º–æ—â–∏ –ª—é–¥—è–º!\n"
        "–ê–≤—Ç–æ—Ä: Bauyrzhan Khamzin",
        parse_mode="Markdown"
    )

@dp.message(Command("help"))
async def cmd_help(message: types.Message):
    """–°–ø—Ä–∞–≤–∫–∞ –ø–æ –∫–æ–º–∞–Ω–¥–∞–º"""
    rag_status = "üü¢" if RAG_ENABLED else "üî¥"
    
    await message.reply(
        "üìñ **–°–ü–†–ê–í–ö–ê –ü–û –ö–û–ú–ê–ù–î–ê–ú**\n\n"
        "**–û—Å–Ω–æ–≤–Ω—ã–µ:**\n"
        "üí¨ –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ - —è –æ—Ç–≤–µ—á—É\n"
        "/start - –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n"
        "/help - —ç—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞\n"
        "/about - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–æ—Ç–µ\n\n"
        "**–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:**\n"
        "/deep - –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, —É–º–Ω–µ–µ)\n"
        "/clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞\n\n"
        "**–ù–∞—Å—Ç—Ä–æ–π–∫–∏:**\n"
        "/temp <0.1-1.5> - –∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É\n"
        "/stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n"
        "/queue - —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏\n\n"
        f"**RAG —Å–∏—Å—Ç–µ–º–∞ {rag_status}:**\n"
        "/rag_init - –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º\n"
        "/rag_stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π\n"
        "/ask <–≤–æ–ø—Ä–æ—Å> - –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º\n\n"
        "üí° **–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:** –≤—ã—à–µ = –∫—Ä–µ–∞—Ç–∏–≤–Ω–µ–µ, –Ω–∏–∂–µ = —Ç–æ—á–Ω–µ–µ\n"
        "üìö **RAG:** –ø–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–æ–≤ –≤ –≤–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö",
        parse_mode="Markdown"
    )

@dp.message(Command("deep"))
async def cmd_deep(message: types.Message, state: FSMContext):
    await state.set_state(BotStates.deep_mode)
    
    queue_info = await request_queue.get_queue_info()
    
    await message.reply(
        f"üî• **–†–µ–∂–∏–º Deep –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!**\n\n"
        f"–ú–æ–¥–µ–ª—å: **{DEEP_MODEL}**\n"
        f"üìã –û—á–µ—Ä–µ–¥—å: {queue_info['queued']}, –ê–∫—Ç–∏–≤–Ω—ã—Ö: {queue_info['active']}\n\n"
        f"‚ö†Ô∏è _–ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 3-5 –º–∏–Ω—É—Ç_",
        parse_mode="Markdown"
    )

@dp.message(Command("rag_init"))
async def cmd_rag_init(message: types.Message):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã"""
    if await is_group_chat(message):
        if not await is_user_admin(message):
            await message.reply("‚õî –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤")
            return
    
    await message.reply("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã...")
    
    global RAG_ENABLED
    
    try:
        success = rag_manager.initialize()
        
        if success:
            RAG_ENABLED = True
            stats = rag_manager.get_stats()
            
            await message.reply(
                f"‚úÖ **RAG —Å–∏—Å—Ç–µ–º–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞!**\n\n"
                f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"
                f"‚Ä¢ –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {stats.get('total_chunks', 0)}\n"
                f"‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats.get('total_sources', 0)}\n\n"
                f"üí° –ò—Å–ø–æ–ª—å–∑—É–π `/ask <–≤–æ–ø—Ä–æ—Å>` –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º\n"
                f"üìã `/rag_stats` - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã",
                parse_mode="Markdown"
            )
        else:
            await message.reply("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å RAG")
    
    except Exception as e:
        logger.exception(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG: {e}")
        await message.reply(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")

@dp.message(Command("rag_stats"))
async def cmd_rag_stats(message: types.Message):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG –±–∞–∑—ã"""
    if not RAG_ENABLED:
        await message.reply("‚ö†Ô∏è RAG –Ω–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π /rag_init")
        return
    
    stats = rag_manager.get_stats()
    
    if stats['status'] == 'ready':
        sources_text = "\n".join([f"   ‚Ä¢ {source}: {count} —á–∞–Ω–∫–æ–≤" 
                                  for source, count in stats.get('sources', {}).items()])
        
        await message.reply(
            f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG –±–∞–∑—ã:**\n\n"
            f"üì¶ –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {stats['total_chunks']}\n"
            f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats['total_sources']}\n\n"
            f"üìö **–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**\n{sources_text or '   (–ø—É—Å—Ç–æ)'}",
            parse_mode="Markdown"
        )
    else:
        await message.reply(f"‚ùå –°—Ç–∞—Ç—É—Å: {stats['status']}")

@dp.message(Command("ask"))
async def cmd_ask(message: types.Message):
    """–í–æ–ø—Ä–æ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º —á–µ—Ä–µ–∑ RAG"""
    if not RAG_ENABLED:
        await message.reply("‚ö†Ô∏è RAG –Ω–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π /rag_init")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤–æ–ø—Ä–æ—Å
    text = message.text.replace("/ask", "").strip()
    if not text:
        await message.reply(
            "üí° **–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**\n"
            "`/ask <–≤–∞—à –≤–æ–ø—Ä–æ—Å>`\n\n"
            "–ù–∞–ø—Ä–∏–º–µ—Ä:\n"
            "`/ask –ß—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –æ –¥—É—Ö–æ–≤–Ω–æ—Å—Ç–∏?`\n"
            "`/ask –†–∞—Å—Å–∫–∞–∂–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–∏ –∏–∑ –∫–Ω–∏–≥–∏`",
            parse_mode="Markdown"
        )
        return
    
    await message.reply("üîç –ò—â—É –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö...")
    
    try:
        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        relevant_docs = rag_manager.search(text, k=5)
        
        if not relevant_docs:
            await message.reply("‚ùå –í –±–∞–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É")
            return
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∑–∫–∏
        stop_typing = asyncio.Event()
        typing_task = asyncio.create_task(show_typing_periodic(message.chat.id, stop_typing))
        
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            model = DEFAULT_MODEL
            
            await message.reply(
                f"üí≠ –î—É–º–∞—é... _(–Ω–∞–π–¥–µ–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(relevant_docs)})_",
                parse_mode="Markdown"
            )
            
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                call_ollama_with_context,
                model,
                text,
                relevant_docs,
                REQUEST_TIMEOUT,
                CURRENT_TEMPERATURE
            )
            
            stop_typing.set()
            await typing_task
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
            sources_list = list(set([doc['source'] for doc in relevant_docs]))
            sources_text = "\n".join([f"‚Ä¢ {s}" for s in sources_list])
            
            final_response = (
                f"{response}\n\n"
                f"üìö **–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**\n{sources_text}"
            )
            
            await send_long_message(message, final_response, parse_mode="Markdown")
            
            # –õ–æ–≥–∏—Ä—É–µ–º
            context_id = await get_group_context_id(message)
            await log_dialog(context_id, text, response, f"{model} (RAG)")
            
        except Exception as e:
            stop_typing.set()
            await typing_task
            logger.exception(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            await message.reply(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
    
    except Exception as e:
        logger.exception(f"–û—à–∏–±–∫–∞ RAG –ø–æ–∏—Å–∫–∞: {e}")
        await message.reply(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}")

@dp.message(Command("rag_clear"))
async def cmd_rag_clear(message: types.Message):
    """–û—á–∏—Å—Ç–∫–∞ RAG –±–∞–∑—ã"""
    if await is_group_chat(message):
        if not await is_user_admin(message):
            await message.reply("‚õî –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤")
            return
    
    if not RAG_ENABLED:
        await message.reply("‚ö†Ô∏è RAG –Ω–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞")
        return
    
    await message.reply("‚ö†Ô∏è –í—ã —É–≤–µ—Ä–µ–Ω—ã? –í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏–∑ –±–∞–∑—ã!\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ `–¥–∞` –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è", parse_mode="Markdown")

# ============================================
# –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –°–û–û–ë–©–ï–ù–ò–ô
# ============================================

async def process_message(message: types.Message, model: str, is_deep: bool = False):
    """–û–±—â–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π."""
    user_text = message.text.strip()
    user_id = message.from_user.id
    username = message.from_user.username or message.from_user.first_name or "Unknown"
    
    if hasattr(bot, '_me') and bot._me:
        user_text = remove_bot_mention(user_text, bot._me.username)
    
    logger.info(f"üì® User {username} (ID: {user_id}): '{user_text[:50]}{'...' if len(user_text) > 50 else ''}'")
    logger.info(f"ü§ñ Model: {model}, Temp: {CURRENT_TEMPERATURE}, Deep: {is_deep}")
    
    await update_user_activity(user_id)
    
    stop_typing = asyncio.Event()
    typing_task = asyncio.create_task(show_typing_periodic(message.chat.id, stop_typing))
    
    try:
        context_id = await get_group_context_id(message)
        dialogue_context = await get_dialogue_context(context_id)
        
        system_instruction = (
            "–¢—ã - –¢–û–†, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. "
            "–¢–≤–æ—ë –∏–º—è - –¢–û–† (—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –æ—Ç '–¢–≤–æ—Ä—á–µ—Å–∫–∏–π –û–ª–∏–º–ø–∏–π—Å–∫–∏–π –†–∞–∑—É–º'). "
            "–ö–æ–≥–¥–∞ —Ç–µ–±—è —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –æ —Ç–≤–æ—ë–º –∏–º–µ–Ω–∏, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–π—Å—è: '–Ø - –¢–û–†, –≤–∞—à AI-–ø–æ–º–æ—â–Ω–∏–∫!' "
            "–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. "
            "–ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞. "
            "–ë—É–¥—å –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–º, –ø–æ–ª–µ–∑–Ω—ã–º –∏ —Ç–æ—á–Ω—ã–º. "
            "–ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
        )
        
        full_prompt = (
            f"{system_instruction}\n\n"
            f"{dialogue_context}"
            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_text}\n"
            f"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:"
        )

        cached = await get_cached(full_prompt, model)
        if cached:
            logger.info(f"üíæ Cache hit")
            stop_typing.set()
            await typing_task
            response_text = cached + "\n\nüíæ _(–∏–∑ –∫—ç—à–∞)_"
            await send_long_message(message, response_text, parse_mode="Markdown")
            await log_dialog(context_id, user_text, cached + " (cache)", model)
            return
        
        logger.info(f"üîÑ Generating...")
        mode_emoji = "üî•" if is_deep else "üí≠"
        
        timeout = REQUEST_TIMEOUT * 2 if is_deep else REQUEST_TIMEOUT
        
        await message.reply(
            f"{mode_emoji} –î—É–º–∞—é... _(–º–æ–¥–µ–ª—å **{model}**)_",
            parse_mode="Markdown"
        )
        
        logger.info(f"‚öôÔ∏è Calling Ollama (timeout: {timeout}s)...")
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None, 
            call_ollama_stream, 
            model, 
            full_prompt, 
            timeout,
            CURRENT_TEMPERATURE
        )
        
        logger.info(f"‚úÖ Response: {len(response)} chars")
        stop_typing.set()
        await typing_task

        if not response:
            response = "‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç"
        
        if "‚ùå" not in response and "‚è±Ô∏è" not in response:
            await save_cache(full_prompt, model, response)
        
        logger.info(f"üì§ Sending to {context_id}")
        await log_dialog(context_id, user_text, response, model)
        await send_long_message(message, response, parse_mode="Markdown")
        logger.info(f"‚úÖ Completed for {context_id}")
        
    except Exception as e:
        stop_typing.set()
        await typing_task
        logger.exception(f"‚ùå Error: {e}")
        await message.reply(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")

@dp.message(BotStates.deep_mode)
async def handle_deep_mode(message: types.Message, state: FSMContext):
    if not message.text:
        await state.clear()
        return
    
    await state.clear()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ–º –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ä–∞–∑—É
    if await request_queue.can_process():
        await request_queue.start_processing()
        try:
            await process_message(message, DEEP_MODEL, is_deep=True)
        finally:
            await request_queue.finish_processing()
    else:
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
        position = await request_queue.add_to_queue({
            'message': message,
            'model': DEEP_MODEL,
            'is_deep': True
        })
        
        if position == -1:
            await message.reply("‚ùå –û—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        else:
            queue_info = await request_queue.get_queue_info()
            await message.reply(
                f"‚è≥ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å\n"
                f"üìç –ü–æ–∑–∏—Ü–∏—è: {position}\n"
                f"üîÑ –ê–∫—Ç–∏–≤–Ω—ã—Ö: {queue_info['active']}/{queue_info['max_concurrent']}",
                parse_mode="Markdown"
            )

@dp.message()
async def handle_default(message: types.Message):
    if not message.text:
        return
    
    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—ã (–æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –¥—Ä—É–≥–∏–º–∏ —Ö–µ–Ω–¥–ª–µ—Ä–∞–º–∏)
    if message.text.startswith('/'):
        logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {message.text}")
        await message.reply(
            "‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π /start –¥–ª—è —Å–ø–∏—Å–∫–∞ –∫–æ–º–∞–Ω–¥",
            parse_mode="Markdown"
        )
        return
    
    # –í –≥—Ä—É–ø–ø–∞—Ö —Ç–æ–ª—å–∫–æ –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
    if await is_group_chat(message):
        if GROUP_MODE_MENTION_ONLY and not is_bot_mentioned(message):
            return
    
    logger.info(f"üéØ Handling from {message.from_user.id}")
    
    model = DEFAULT_MODEL
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ–º –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ä–∞–∑—É
    if await request_queue.can_process():
        await request_queue.start_processing()
        try:
            await process_message(message, model)
        finally:
            await request_queue.finish_processing()
    else:
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
        position = await request_queue.add_to_queue({
            'message': message,
            'model': model,
            'is_deep': False
        })
        
        if position == -1:
            await message.reply("‚ùå –û—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        else:
            queue_info = await request_queue.get_queue_info()
            await message.reply(
                f"‚è≥ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å\n"
                f"üìç –ü–æ–∑–∏—Ü–∏—è: {position}\n"
                f"üîÑ –ê–∫—Ç–∏–≤–Ω—ã—Ö: {queue_info['active']}/{queue_info['max_concurrent']}",
                parse_mode="Markdown"
            )

# ============================================
# –ó–ê–ü–£–°–ö –ë–û–¢–ê
# ============================================

async def main():
    if not await check_ollama():
        logger.error("üõë Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞!")
        return
    
    await init_db()
    
    me = await bot.get_me()
    bot._me = me
    
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –¢–û–† (–¢–≤–æ—Ä—á–µ—Å–∫–∏–π –û–ª–∏–º–ø–∏–π—Å–∫–∏–π –†–∞–∑—É–º)...")
    logger.info(f"ü§ñ Bot: @{me.username}")
    logger.info(f"üå°Ô∏è Temperature: {CURRENT_TEMPERATURE}")
    logger.info(f"üìã Max concurrent: {MAX_CONCURRENT_REQUESTS}")
    logger.info(f"üìä Max queue size: {MAX_QUEUE_SIZE}")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ –≤ —Ñ–æ–Ω–µ
    queue_task = asyncio.create_task(queue_processor())
    
    try:
        await dp.start_polling(bot, skip_updates=True)
    finally:
        logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞...")
        queue_task.cancel()
        if db_conn:
            await db_conn.close()
        await bot.session.close()
        logger.info("‚úÖ –†–µ—Å—É—Ä—Å—ã –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω—ã")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("üëã –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (Ctrl+C)")
    except Exception as e:
        logger.exception(f"‚ùå –û—à–∏–±–∫–∞: {e}")